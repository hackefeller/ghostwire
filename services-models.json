{
  "ai_coding_strategy_2026": {
    "version": "1.2",
    "currency": "USD",
    "situations": [
      {
        "scenario": "Continuous Multi-file Debugging",
        "description": "Debugging a logic error across 3-4 files with 10+ back-and-forth messages.",
        "recommended_service": "OpenCode (API)",
        "recommended_model": "Claude Sonnet 4.5",
        "math_justification": "OpenCode's 'Cached Read' at $0.30/1M tokens is 90% cheaper for follow-up prompts. A flat-fee service would charge $0.40+ for the same 10 messages, regardless of repetitive context.",
        "estimated_cost": "$0.01 - $0.05 total"
      },
      {
        "scenario": "Legacy Code Modernization",
        "description": "Pasting a massive 50k line 'God Object' and asking for a full rewrite in a new framework.",
        "recommended_service": "GitHub Copilot (Subscription)",
        "recommended_model": "GPT-5.2-Codex",
        "math_justification": "Massive fresh inputs exceed the 'break-even' point for API tokens. At $3/1M input, a 100k token file costs $0.30 on OpenCode, but only one 'Premium Request' ($0.04) on Copilot.",
        "estimated_cost": "$0.04 (1 Credit)"
      },
      {
        "scenario": "Agentic Task Automation",
        "description": "Using an AI agent to crawl your repo, run tests, fix errors, and commit automatically.",
        "recommended_service": "OpenCode (API)",
        "recommended_model": "Claude Haiku 4.5",
        "math_justification": "Agents are 'chatty.' They might make 50 tiny calls to solve one bug. At $0.04/request on Copilot, that's $2.00. On OpenCode, 50 small calls with Haiku cost less than $0.15.",
        "estimated_cost": "< $0.20 per task"
      },
      {
        "scenario": "High-Latency UI/UX Tweaks",
        "description": "Small CSS/HTML alignment fixes where speed is more important than deep reasoning.",
        "recommended_service": "OpenCode (API)",
        "recommended_model": "Grok Code Fast 1",
        "math_justification": "Grok's output speed (270+ tok/s) and ultra-low input price ($0.20/1M) make it ideal for 'vibe coding' where you just want to see immediate changes for pennies.",
        "estimated_cost": "$0.001 per request"
      },
      {
        "scenario": "Complex Systems Architecture",
        "description": "Brainstorming a distributed system or database schema with a reasoning-heavy model.",
        "recommended_service": "GitHub Copilot (Subscription)",
        "recommended_model": "Claude Opus 4.5",
        "math_justification": "Reasoning models like Opus often have 10x-50x multipliers. On a $10 Pro plan, one prompt might cost $0.40 worth of credits, which is still cheaper than the $15-$25/1M token API rate for deep thinking.",
        "estimated_cost": "$0.04 - $0.40 (1-10 Credits)"
      },
      {
        "scenario": "Offline / Privacy-Critical Coding",
        "description": "Working on sensitive internal IP or while traveling without reliable internet.",
        "recommended_service": "Local LLM (Ollama/Llama.cpp)",
        "recommended_model": "Qwen 32B Coder",
        "math_justification": "Zero variable cost. After the initial $2,000 - $10,000 hardware investment (GPU), every token is 'free.' Best ROI for 1M+ tokens per month of usage.",
        "estimated_cost": "$0.00 (post-hardware)"
      }
    ]
  }
}
